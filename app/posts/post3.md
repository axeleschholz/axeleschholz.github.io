---
title: "Journal 4"
author: "Axel Eschholz"
---

### Technological and Ethical Impacts: Dive deep into the ethical challenges of the AI age, especially in terms of biased algorithms. How can developers ensure fairness and transparency in machine learning models?

That is the million dollar question. As we discussed in class, an AI’s perspective on the world is entirely determined by its training data, much like a human’s perspective is determined by their life experience. However, presenting an AI with truly “unbiased” data, if that is even possible, is exceedingly difficult. This is because the entirety of human history and texts are biased in some way. For example, if you feed an AI western historical texts written over the last 100 years, it will undeniably develop the white colonial bias inherent in the overwhelming majority of the works. Similarly, if you train the AI on the last 5 years of Reddit and Twitter posts, it would become an unhinged reflection of the worst instincts of humanity. Thus the problem of eliminating bias in AI becomes the problem of curating an unbiased reflection of the world.

To go a bit beyond the point at hand, this conundrum is indicative of a fascinating shift in the field of AI research. As models become sufficiently complex, dense, and obscure, the practice of AI development becomes much less hard science and more akin to philosophy. As the technical aspects continue to be abstracted away, effective AI development may prioritize comprehensive knowledge of sociology and philosophy over technical skill. In an extreme example it’s amusing to consider that we might come full circle, where a Bachelor of Psychology graduate is making three times the starting salary of a computer scientist right out of school.
